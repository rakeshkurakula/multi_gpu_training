{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch go-to choice for researchers and practitioners for building deep learning models.\n",
    "- It has some inherient problems like:\n",
    "    1. Managing training loops\n",
    "    2. Logging\n",
    "    3. Handling Distributed training\n",
    "    4. Debugging in a distributed setting\n",
    "    5. Mixed precision training\n",
    "    6. Running models on TPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.3688920587301254, Accuracy: 0.104\n",
      "Epoch 2, Loss: 2.3498924151062965, Accuracy: 0.097\n",
      "Epoch 3, Loss: 2.335986942052841, Accuracy: 0.099\n",
      "Epoch 4, Loss: 2.3231282085180283, Accuracy: 0.101\n",
      "Epoch 5, Loss: 2.3174316734075546, Accuracy: 0.099\n"
     ]
    }
   ],
   "source": [
    "# Define the dataset\n",
    "train_dataset = torch.utils.data.TensorDataset(torch.randn(1000, 2), torch.randint(0, 10, (1000,)))\n",
    "test_dataset = torch.utils.data.TensorDataset(torch.randn(1000, 2), torch.randint(0, 10, (1000,)))\n",
    "val_dataset = torch.utils.data.TensorDataset(torch.randn(1000, 2), torch.randint(0, 10, (1000,)))\n",
    "\n",
    "# Defining the model class inherited from PyTorch's nn.Module class\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(2, 10)\n",
    "        self.fc2 = nn.Linear(10, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "# Define the loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define the evaluate function with proper batching\n",
    "def evaluate(model):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return correct / total\n",
    "\n",
    "# we have declared the model without backward pass explicitly\n",
    "epochs = 5\n",
    "model = MyModel()\n",
    "# Defining the optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for inputs, labels in trainloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    accuracy = evaluate(model)\n",
    "    # print the loss and accuracy\n",
    "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(trainloader)}, Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As discussed above there are problems with PyTorch\n",
    "\n",
    "# PyTorch Lighting \n",
    "- Solves the above discussed challenges\n",
    "\n",
    "- Managing training loops: PyTorch Lightning simplifies this process by providing a high-level abstraction for defining the training loop, reducing the amount of boilerplate code required.\n",
    "- Logging: PyTorch Lightning integrates with popular logging frameworks like TensorBoard and Comet, making it easier to log training metrics and visualize them in real-time.\n",
    "Handling distributed training: PyTorch Lightning simplifies distributed training by providing a unified interface. This abstracts away the complexity of the underlying implementation.\n",
    "- Debugging in a distributed setting: PyTorch Lightning provides tools and utilities to facilitate debugging in a distributed setting, making it easier to identify and resolve issues.\n",
    "- Mixed-precision training: PyTorch Lightning simplifies mixed-precision training by providing utilities to automatically handle the precision of operations based on user-defined settings.\n",
    "- Running models on TPUs: PyTorch Lightning supports running models on TPUs, abstracting away the complexity of the underlying TPU architecture and allowing users to focus on their model implementation.\n",
    "\n",
    "# PyTorch to PyTorch Lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definint the PyTorch model\n",
    "\n",
    "# importing the required packages and libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the dataset\n",
    "\n",
    "# 1) Data transformer\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# 2) Create Train dataset\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True, \n",
    "                                      download=True, transform=transform)\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "# 3) Create Test dataset\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False, \n",
    "                                     download=True, transform=transform)\n",
    "\n",
    "# 4) Create DataLoader\n",
    "testloader = DataLoader(testset, batch_size=64, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now that the data is loaded, we can define the model\n",
    "\n",
    "class PyTorchNet(nn.Module):\n",
    "    \n",
    "    # Defining the architecture of the model\n",
    "    def __init__(self):\n",
    "        super(PyTorchNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 512)\n",
    "        self.fc2 = nn.Linear(512, 1024)\n",
    "        self.fc3 = nn.Linear(1024, 128)\n",
    "        self.fc4 = nn.Linear(128, 10)\n",
    "\n",
    "    # Defining the forward pass\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "    \n",
    "# Initialzie the model and define the loss function and optimizer\n",
    "model = PyTorchNet()\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Define loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define a evaluation methods\n",
    "def evaluate(model):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            inputs, labels = data\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1,\n",
      "          Loss: 0.29247100143306165,\n",
      "          Accuracy: 0.9276\n",
      "          \n",
      "Epoch 2,\n",
      "          Loss: 0.14089426057470808,\n",
      "          Accuracy: 0.9632\n",
      "          \n",
      "Epoch 3,\n",
      "          Loss: 0.107698312252889,\n",
      "          Accuracy: 0.9661\n",
      "          \n",
      "Epoch 4,\n",
      "          Loss: 0.09020289394017587,\n",
      "          Accuracy: 0.9727\n",
      "          \n",
      "Epoch 5,\n",
      "          Loss: 0.0748992892322756,\n",
      "          Accuracy: 0.9729\n",
      "          \n"
     ]
    }
   ],
   "source": [
    "## Train the model\n",
    "\n",
    "# Define the number of epochs\n",
    "epochs = 5\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for data in trainloader:\n",
    "\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    accuracy = evaluate(model)\n",
    "\n",
    "    print(f\"\"\"Epoch {epoch + 1},\n",
    "          Loss: {running_loss / len(trainloader)},\n",
    "          Accuracy: {accuracy}\n",
    "          \"\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install lightning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch Lightning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "\n",
    "class PyTorchLightningNet(pl.LightningModule):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(PyTorchLightningNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 512)\n",
    "        self.fc2 = nn.Linear(512, 1024)\n",
    "        self.fc3 = nn.Linear(1024, 128)\n",
    "        self.fc4 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "model = PyTorchLightningNet()\n",
    "# Define optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Define loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define a evaluation methods\n",
    "def evaluate(model):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            inputs, labels = data\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1,\n",
      "          Loss: 0.30681939999352514,\n",
      "          Accuracy: 0.9312\n",
      "          \n",
      "Epoch 2,\n",
      "          Loss: 0.1400705497435876,\n",
      "          Accuracy: 0.9451\n",
      "          \n",
      "Epoch 3,\n",
      "          Loss: 0.10690825645710582,\n",
      "          Accuracy: 0.9624\n",
      "          \n",
      "Epoch 4,\n",
      "          Loss: 0.09134310164175101,\n",
      "          Accuracy: 0.9683\n",
      "          \n",
      "Epoch 5,\n",
      "          Loss: 0.07344570693729727,\n",
      "          Accuracy: 0.9702\n",
      "          \n"
     ]
    }
   ],
   "source": [
    "## Train the model\n",
    "\n",
    "# Define the number of epochs\n",
    "epochs = 5\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for data in trainloader:\n",
    "\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    accuracy = evaluate(model)\n",
    "\n",
    "    print(f\"\"\"Epoch {epoch + 1},\n",
    "          Loss: {running_loss / len(trainloader)},\n",
    "          Accuracy: {accuracy}\n",
    "          \"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Looks like there is more variation in the accuracy\n",
    "\n",
    "To do this we can add things to out Lightining model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Trainer.__init__() got an unexpected keyword argument 'PYTORCH_MPS_HIGH_WATERMARK_RATIO'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 114\u001b[39m\n\u001b[32m    112\u001b[39m \u001b[38;5;66;03m# Initialize model and trainer\u001b[39;00m\n\u001b[32m    113\u001b[39m model = MNISTLightningModel()\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m trainer = \u001b[43mpl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTrainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    115\u001b[39m \u001b[43m                     \u001b[49m\u001b[43maccelerator\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mauto\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    116\u001b[39m \u001b[43m                     \u001b[49m\u001b[43mPYTORCH_MPS_HIGH_WATERMARK_RATIO\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    117\u001b[39m \u001b[43m                     \u001b[49m\u001b[43mprecision\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m16\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[43m                     \u001b[49m\u001b[43mlog_every_n_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    119\u001b[39m \u001b[43m                     \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mTrainingProgressCallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    121\u001b[39m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[32m    122\u001b[39m trainer.fit(model, train_loader, val_loader)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/multi_gpu_training/.venv/lib/python3.12/site-packages/pytorch_lightning/utilities/argparse.py:70\u001b[39m, in \u001b[36m_defaults_from_env_vars.<locals>.insert_env_defaults\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     67\u001b[39m kwargs = \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mlist\u001b[39m(env_variables.items()) + \u001b[38;5;28mlist\u001b[39m(kwargs.items()))\n\u001b[32m     69\u001b[39m \u001b[38;5;66;03m# all args were already moved to kwargs\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: Trainer.__init__() got an unexpected keyword argument 'PYTORCH_MPS_HIGH_WATERMARK_RATIO'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import pytorch_lightning as pl\n",
    "import torchmetrics\n",
    "import os\n",
    "\n",
    "# Set environment variable for MPS to avoid OOM errors\n",
    "os.environ[\"PYTORCH_MPS_HIGH_WATERMARK_RATIO\"] = \"0.0\"\n",
    "\n",
    "# Empty MPS cache before training (helps free up memory)\n",
    "if torch.backends.mps.is_available():\n",
    "    torch.mps.empty_cache()\n",
    "\n",
    "# Data transformation\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "val_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "class TrainingProgressCallback(pl.Callback):\n",
    "\n",
    "    def on_train_start(self, trainer, pl_module):\n",
    "        print(\"Starting training!!\")\n",
    "\n",
    "# Define Lightning model\n",
    "class MNISTLightningModel(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(28 * 28, 512),  # First FC layer\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 1024),  # Second FC layer\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 256),  # Third FC layer\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),  # Fourth FC layer\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 10)  # Output layer\n",
    "        )\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        # Define torchmetrics for tracking\n",
    "        self.accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=10)\n",
    "        self.precision = torchmetrics.Precision(task=\"multiclass\", num_classes=10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)  # Flatten input\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        inputs, labels = batch\n",
    "        outputs = self(inputs)\n",
    "        loss = self.criterion(outputs, labels)\n",
    "\n",
    "        # Compute metrics (convert logits to class predictions)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "\n",
    "        acc = self.accuracy(preds, labels)\n",
    "        prec = self.precision(preds, labels)\n",
    "\n",
    "        # Log metrics separately\n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        self.log('train_acc', acc, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        self.log('train_precision', prec, on_step=True, on_epoch=True, prog_bar=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        inputs, labels = batch\n",
    "        outputs = self(inputs)\n",
    "        loss = self.criterion(outputs, labels)\n",
    "\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        acc = self.accuracy(preds, labels)\n",
    "\n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "        self.log('val_acc', acc, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        inputs, labels = batch\n",
    "        outputs = self(inputs)\n",
    "        loss = self.criterion(outputs, labels)\n",
    "\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        acc = self.accuracy(preds, labels)\n",
    "\n",
    "        self.log('test_loss', loss, prog_bar=True)\n",
    "        self.log('test_acc', acc, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return optim.Adam(self.parameters(), lr=0.001)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return train_loader\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return val_loader\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return test_loader\n",
    "\n",
    "\n",
    "# Initialize model and trainer\n",
    "model = MNISTLightningModel()\n",
    "trainer = pl.Trainer(max_epochs=4,\n",
    "                     accelerator= \"auto\",\n",
    "                     PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0,\n",
    "                     precision=16,\n",
    "                     log_every_n_steps=10,\n",
    "                     callbacks=[TrainingProgressCallback()])\n",
    "\n",
    "# Train the model\n",
    "trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "# Test the model\n",
    "trainer.test(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation DataLoader 0: 100%|██████████| 157/157 [00:01<00:00, 125.57it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "     Validate metric           DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "         val_acc            0.9702000021934509\n",
      "        val_loss            0.09746826440095901\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Testing DataLoader 0: 100%|██████████| 157/157 [00:01<00:00, 134.46it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc            0.9702000021934509\n",
      "        test_loss           0.09746826440095901\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.09746826440095901, 'test_acc': 0.9702000021934509}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Valiation run\n",
    "trainer.validate(model, val_loader)\n",
    "\n",
    "# Test run\n",
    "trainer.test(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.predict(model, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model):\n",
    "\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            inputs, labels = data\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
